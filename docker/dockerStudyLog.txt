
Part one: get a image and run a container

/*
The docker run command first starts a docker pull to download the Ubuntu image onto your host.
After it is downloaded, it will start the container.
*/
docker container run -t ubuntu top

Containers:
Containers use Linux namespaces to provide isolation of system resources from other containers or the host.
The container does not have its own kernel. 
It uses the kernel of the host and 
the Ubuntu image is used only to provide the file system and tools available on an Ubuntu system.

/*
Interact with this container from your terminal, use the -it flag to run using interactive mode 
while allocating a psuedo-terminal:
Using docker container exec with bash is a common way to inspect a Docker container.
Remember that containers use kernel-level features to achieve isolation and 
that containers run on top of the kernel. Your container is just a group of processes running in isolation 
on the same host, and you can use the command "docker container exec" to enter that isolation with the bash process.
*/
docker container exec -it 063d7d182d58 bash

Linux:
PID is just one of the Linux namespaces that provides containers with isolation to system resources. 
Other Linux namespaces include:
MNT: Mount and unmount directories without affecting other namespaces.
NET: Containers have their own network stack.
IPC: Isolated interprocess communication mechanisms such as message queues.
User: Isolated view of users on the system.
UTC: Set hostname and domain name per container.

/**********************************************************************************************
/**********************************************************************************************
Part Two: run multi containers. 
==================================================================================
The Docker Store is the public central registry for Docker images. 
Anyone can share images here publicly. 
The Docker Store contains community and official images that can also be found on the Docker Hub.
==================================================================================
/*
Run an NGINX server by using the official NGINX image from the Docker Store.
14bef1b4f661
The --detach flag will run this container in the background. 
The --publish flag publishes port 80 in the container (the default port for NGINX) by using port 8080 on your host. 
Remember that the NET namespace gives processes of the container their own network stack. 
The --publish flag is a feature that can expose networking through the container onto the host.
the --name flag, which names the container. Every container has a name. 
If you don't specify one, Docker will randomly assign one for you.

*/
docker container run --detach --publish 8080:80 --name nginx nginx

/*
get a mongo image
*/
docker container run --detach --publish 8081:27017 --name mongo mongo:3.4


Running multiple containers on the same host gives us the ability to use the resources (CPU, memory, 
and so on) available on single host. This can result in huge cost savings for an enterprise.

/**********************************************************************************************
/**********************************************************************************************
Part Three: Stop and Remove Containers
/*stop*/
docker container stop [container id]
/*remove
Remove the stopped containers. The following command removes any stopped containers, 
unused volumes and networks, and dangling images
*/
docker system prune


/**********************************************************************************************
/**********************************************************************************************
create a docker image self

The root dir is
C:\Program Files\Git
The default dir is 
E:\PF\Docker Toolbox

1. Create a file named Dockerfile and add the following content:
FROM python:3.6.1-alpine
RUN pip install flask
CMD ["python","app.py"]
COPY app.py /app.py

FROM python:3.6.1-alpine: --select a parent as base layer
This is the starting point for your Dockerfile. 
Every Dockerfile typically starts with a FROM line that is the starting image to build your layers on top of.
Here you are using the 3.6.1-alpine tag for the Python image.
It is best practice to use a specific tag when inheriting a parent image so that 
changes to the parent dependency are controlled.
For security reasons, you must understand the layers that you build your docker image on top of. 
For that reason, it is highly recommended to only use official images found in the Docker Hub, 
or noncommunity images found in the Docker Store. 

RUN pip install flask: --install necessary tools or packages
The RUN command executes commands needed to set up your image for your application, 
such as installing packages, editing files, or changing file permissions. 
In this case, you are installing Flask. The RUN commands are executed at build time 
and are added to the layers of your image.

CMD ["python","app.py"]:  --the entry while starting a container
CMD is the command that is executed when you start a container. 
Here, you are using CMD to run your Python applcation.
There can be only one CMD per Dockerfile. 
If you specify more than one CMD, then the last CMD will take effect. 

COPY app.py /app.py :  --copy local files or packages to a new layer of the image
This line copies the app.py file in the local directory (where you will run docker image build) 
into a new layer of the image. 

2. create a new image by the Dockerfile created in step1
//create new image
$ docker image build -t python-hello-world .
//run the new created image
docker run -p 5001:5000 -d python-hello-world


/**********************************************************************************************
/**********************************************************************************************
get docker host info

docker-machine env: 
export DOCKER_TLS_VERIFY="1"
export DOCKER_HOST="tcp://192.168.99.100:2376"
export DOCKER_CERT_PATH="C:\Users\IBM_ADMIN\.docker\machine\machines\default"
export DOCKER_MACHINE_NAME="default"
export COMPOSE_CONVERT_WINDOWS_PATHS="true"
# Run this command to configure your shell:
# eval $("E:\PF\Docker Toolbox\docker-machine.exe" env)


/**********************************************************************************************
/**********************************************************************************************
push a image to remote registry center

take Docker Hub as a remote registry center:
1.login Docker Hub first:
docker login
2.The Docker Hub naming convention is to tag your image with [dockerhub username]/[image name]. 
To do this, tag your previously created image python-hello-world to fit that format.
docker tag python-hello-world [dockerhub username]/python-hello-world
3.use the docker push command to push your image to the Docker Hub registry
docker push [dockerhub username]/python-hello-world
$ docker push rockrockrockwong/python-hello-world
The push refers to repository [docker.io/rockrockrockwong/python-hello-world]
276be7532b45: Pushed
e6cc17b9d5fe: Pushed
5f354b8b5dc0: Mounted from library/python
f61107386c17: Mounted from library/python
db49993833a0: Mounted from library/python
58c71ea40fb0: Mounted from library/python
2b0fb280b60d: Mounted from library/python
latest: digest: sha256:fd134b00d25eaf5c5ba2b90394c3540a23c98821fb706975125e4ee04c6928a6 size: 1786


/**********************************************************************************************
/**********************************************************************************************
deploy a change

1.rebuild the image by following command, of course Dockerfile is in the folder "."
docker image build -t python-hello-world .
$ docker image build -t python-hello-world .
Sending build context to Docker daemon  390.3MB
Step 1/4 : FROM python:3.6.1-alpine
 ---> ddd6300d05a3
Step 2/4 : RUN pip install flask
 ---> Using cache
 ---> c9e0fe6f523a
Step 3/4 : CMD ["python","app.py"]
 ---> Using cache
 ---> 08a9f3f9c9ad
Step 4/4 : COPY app.py /app.py
 ---> 82cde8c6a3f5
Successfully built 82cde8c6a3f5
Successfully tagged python-hello-world:latest

Using cache:
Notice the "Using cache" for Steps 1 - 3. These layers of the Docker image have already been built, 
and the docker image build command will use these layers from the cache instead of rebuilding them.

2.rebuild a image that has registered on remote registry
2.1 rebuild as same as rebuild local image
$ docker image build -t rockrockrockwong/python-hello-world .
Sending build context to Docker daemon  390.3MB
Step 1/4 : FROM python:3.6.1-alpine
 ---> ddd6300d05a3
Step 2/4 : RUN pip install flask
 ---> Using cache
 ---> c9e0fe6f523a
Step 3/4 : CMD ["python","app.py"]
 ---> Using cache
 ---> 08a9f3f9c9ad
Step 4/4 : COPY app.py /app.py
 ---> Using cache
 ---> 82cde8c6a3f5
Successfully built 82cde8c6a3f5
Successfully tagged rockrockrockwong/python-hello-world:latest
2.2 push the rebuilded image to remote registry
$ docker push rockrockrockwong/python-hello-world
The push refers to repository [docker.io/rockrockrockwong/python-hello-world]
a610e73ed84a: Pushed
e6cc17b9d5fe: Layer already exists
5f354b8b5dc0: Layer already exists
f61107386c17: Layer already exists
db49993833a0: Layer already exists
58c71ea40fb0: Layer already exists
2b0fb280b60d: Layer already exists
latest: digest: sha256:6c80362058df2ac902df91782e3f49a6ae254682e36fd7703c82fae5440501f1 size: 1786

There is a caching mechanism in place for pushing layers too. 
Docker Hub already has all but one of the layers from an earlier push, 
so it only pushes the one layer that has changed.

When you change a layer, every layer built on top of that will have to be rebuilt. 
Each line in a Dockerfile builds a new layer that is built on the layer created from the lines before it. 
This is why the order of the lines in your Dockerfile is important. 
You optimized your Dockerfile so that the layer that is most likely 
to change (COPY app.py /app.py) is the last line of the Dockerfile. 
Generally for an application, your code changes at the most frequent rate. This optimization 
is particularly important for CI/CD processes where you want your automation to run as fast as possible.

/**********************************************************************************************
/**********************************************************************************************
Understand image layers

Consider the Dockerfile that you created before:

FROM python:3.6.1-alpine
RUN pip install flask
CMD ["python","app.py"]
COPY app.py /app.py

Each of these lines is a layer. 
Each layer contains only the delta, or changes from the layers before it. 
To put these layers together into a single running container, Docker uses the union file system 
to overlay layers transparently into a single view.

Each layer of the image is read-only except for the top layer, which is created for the container. 
The read/write container layer implements "copy-on-write," which means that files that are 
stored in lower image layers are pulled up to the read/write container layer only when edits 
are being made to those files. Those changes are then stored in the container layer.

The "copy-on-write" function is very fast and in almost all cases, does not have a noticeable 
effect on performance. You can inspect which files have been pulled up to the container level 
with the "docker diff" command. For more information, see the command-line reference on the docker diff command.

Because image layers are read-only, they can be shared by images and by running containers. 
For example, creating a new Python application with its own Dockerfile with similar base 
layers will share all the layers that it had in common with the first Python application.


/**********************************************************************************************
/**********************************************************************************************
stop and remove containers
1.list all running containers
docker container ls
2. stop the container which you want to stop
docker container stop [container id]

Chang Lin@IBM-062987 MINGW64 /e/PF/Docker Toolbox
$ docker container ls
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                     NAMES
053c82f87233        1b67afbdd2be        "python app.py"          2 hours ago         Up 2 hours          0.0.0.0:5001->5000/tcp    awesome_saha
8cc861705452        mongo:3.4           "docker-entrypoint.s"   4 hours ago         Up 4 hours          0.0.0.0:8081->27017/tcp   mongo
14bef1b4f661        nginx               "nginx -g 'daemon of"   7 hours ago         Up 7 hours          0.0.0.0:8080->80/tcp      nginx
063d7d182d58        ubuntu              "top"                    8 hours ago         Up 7 hours                                    dazzling_hoover

Chang Lin@IBM-062987 MINGW64 /e/PF/Docker Toolbox
$ docker container stop 053
053

Chang Lin@IBM-062987 MINGW64 /e/PF/Docker Toolbox
$ docker container ls
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                     NAMES
8cc861705452        mongo:3.4           "docker-entrypoint.s"   4 hours ago         Up 4 hours          0.0.0.0:8081->27017/tcp   mongo
14bef1b4f661        nginx               "nginx -g 'daemon of"   7 hours ago         Up 7 hours          0.0.0.0:8080->80/tcp      nginx
063d7d182d58        ubuntu              "top"                    8 hours ago         Up 7 hours                                    dazzling_hoover

3. Remove the stopped containers by running docker system prune

Chang Lin@IBM-062987 MINGW64 /e/PF/Docker Toolbox
$ docker system prune
WARNING! This will remove:
        - all stopped containers
        - all networks not used by at least one container
        - all dangling images
        - all build cache
Are you sure you want to continue? [y/N] y
Deleted Containers:
053c82f8723348b86ef71f535f27a6f694fd078b74f254a093a16346acf75788
55edbcd7321d5a9a943a3f4f524ea24775df78b963dd715aaa0d90ed42fea5af

Deleted Images:
untagged: rockrockrockwong/python-hello-world@sha256:fd134b00d25eaf5c5ba2b90394c3540a23c98821fb706975125e4ee04c6928a6
deleted: sha256:1b67afbdd2be67e8457be08ad40ea6fb8455b5727c2bfe34ad0392116e15da73
deleted: sha256:bdc27b5881649ce6065bed68ba820cab27117bef583db34d7e6703c327bc675d

Total reclaimed space: 300.5kB

/**********************************************************************************************
/**********************************************************************************************
Summary
you started adding value by creating your own custom Docker containers. Remember these key points:

Use the Dockerfile to create reproducible builds for your application and to integrate your application 
with Docker into the CI/CD pipeline.

Docker images can be made available to all of your environments through a central registry. 
The Docker Hub is one example of a registry, but you can deploy your own registry on servers you control.

A Docker image contains all the dependencies that it needs to run an application within the image. 
This is useful because you no longer need to deal with environment drift (version differences) 
when you rely on dependencies that are installed on every environment you deploy to.

Docker uses of the union file system and "copy-on-write" to reuse layers of images. 
This lowers the footprint of storing images and significantly increases the performance of starting containers.

Image layers are cached by the Docker build and push system. There's no need to rebuild or repush image 
layers that are already present on a system.

Each line in a Dockerfile creates a new layer, and because of the layer cache, the lines that change more 
frequently, for example, adding source code to an image, should be listed near the bottom of the file.


/**********************************************************************************************
/**********************************************************************************************
Docker Swarm
Swarm是Docker官方提供的一款集群管理工具，其主要作用是把若干台Docker主机抽象为一个整体，并且通过一个
入口统一管理这些Docker主机上的各种Docker资源。
Swarm和Kubernetes比较类似，但是更加轻，具有的功能也较kubernetes更少一些。

在所谓的集群中，它可能对应了一到多台的实际服务器。
每台服务器上都装有Docker并且开启了基于HTTP的DockerAPI。
这个集群中有一个SwarmManager的管理者，用来管理集群中的容器资源。
管理者的管理对象不是服务器层面而是集群层面的，也就是说通过Manager，我们只能笼统地向集群发出指令
而不能具体到某台具体的服务器上要干什么（这也是Swarm的根本所在）。
至于具体的管理实现方式，Manager向外暴露了一个HTTP接口，外部用户通过这个HTTP接口来实现对集群的管理。
对于稍微大一点的集群，最好是拿出一台实际的服务器作为专门的管理者，
作为学习而言，也可以把管理者和被管理者放在一台服务器上.

Step1: Choose node 1 as Docker Swarm Manager node.
Initialize the swarm on node 1:
$ docker swarm init --advertise-addr eth0
Swarm initialized: current node (nfmecw75vthozacisy0xzxb2w) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-1e4eck1zq85gkp3tgqm553xq0y4yvmaoe1ge0ddj1jyzu5vsw6-dx0l4nj8eeayemibbe6vhs6y9 192.168.0.28:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.

You can think of Docker Swarm as a special mode that is activated by the command: docker swarm init. 
The --advertise-addr option specifies the address in which the other nodes will use to join the swarm.
This docker swarm init command generates a join token. The token makes sure that no malicious nodes 
join the swarm. You need to use this token to join the other nodes to the swarm. 
For convenience, the output includes the full command docker swarm join, which you can just copy/paste to the other nodes.

Step2:
Adding other nodes to Docker Swarm by running following command on other nodes:
docker swarm join --token SWMTKN-1-1e4eck1zq85gkp3tgqm553xq0y4yvmaoe1ge0ddj1jyzu5vsw6-dx0l4nj8eeayemibbe6vhs6y9 192.168.0.28:2377

Step3:
Back on node1, run docker node ls to verify your three-node cluster:

$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
nfmecw75vthozacisy0xzxb2w *   node1               Ready               Active              Leader              18.06.1-ce
xk7plq0zauiiyndi4h0ojt6y3     node2               Ready               Active                                  18.06.1-ce
au5sohxxp8d4lasbd2j8llbaa     node3               Ready               Active                                  18.06.1-ce

Your node consists of one manager node and two workers nodes. 
Managers handle commands and manage the state of the swarm. 
Workers cannot handle commands and are simply used to run containers at scale. 
By default, managers are also used to run containers.

Although you control the swarm directly from the node in which its running, 
you can control a Docker swarm remotely by connecting to the Docker Engine of the manager 
by using the remote API or by activating a remote host from your local Docker 
installation (using the $DOCKER_HOST and $DOCKER_CERT_PATH environment variables). 
This will become useful when you want to remotely control production applications, 
instead of using SSH to directly control production servers.


/**********************************************************************************************
/**********************************************************************************************
create a service on Docker Swarm manager node: 
$ docker service create --detach=true --name nginx1 --publish 80:80  --mount source=/etc/hostname,target=/usr/share/nginx/html/index.html,type=bind,ro nginx:1.12
xu4cesb2gej9jrbnq4zhc67y0

This command statement is declarative, and Docker Swarm will try to maintain the state declared 
in this command unless explicitly changed by another docker service command. 
This behavior is useful when nodes go down, for example, and containers are automatically 
rescheduled on other nodes. You will see a demonstration of that a little later in this lab.

The --mount flag is useful to have NGINX print out the hostname of the node it's running on. 
You will use this later in this lab when you start load balancing between multiple containers 
of NGINX that are distributed across different nodes in the cluster and you want to see which 
node in the swarm is serving the request.

You are using NGINX tag 1.12 in this command. You will see a rolling update with version 1.13 later in this lab.

The --publish command uses the swarm's built-in routing mesh. In this case, port 80 is exposed on every node 
in the swarm. The routing mesh will route a request coming in on port 80 to one of the nodes running the container.


docker service update --replicas=5 --detach=true nginx1
When this command is run, the following events occur:
The state of the service is updated to 5 replicas, which is stored in the swarm's internal storage.
Docker Swarm recognizes that the number of replicas that is scheduled now does not match the declared state of 5.
Docker Swarm schedules 5 more tasks (containers) in an attempt to meet the declared state for the service.
This swarm is actively checking to see if the desired state is equal to actual state and will attempt to reconcile if needed.

Check the aggregated logs for the service:
docker service logs nginx1



/**********************************************************************************************
/**********************************************************************************************
 Apply rolling updates

 $ docker service update --image nginx:1.13 --detach=true nginx1
 This triggers a rolling update of the swarm. Quickly enter the command docker service ps nginx1 over and over to see the updates in real time.

You can fine-tune the rolling update by using these options:

--update-parallelism: specifies the number of containers to update immediately (defaults to 1).
--update-delay: specifies the delay between finishing updating a set of containers before moving on to the next set.


/**********************************************************************************************
/**********************************************************************************************
Reconcile problems with containers

In the previous section, you updated the state of your service by using the command docker service update. 
You saw Docker Swarm in action as it recognized the mismatch between desired state and actual state, 
and attempted to solve the issue.

The inspect-and-then-adapt model of Docker Swarm enables it to perform reconciliation when something goes wrong. 
For example, when a node in the swarm goes down, it might take down running containers with it. 
The swarm will recognize this loss of containers and will attempt to reschedule containers 
on available nodes to achieve the desired state for that service.

Example:
$ docker service create --detach=true --name nginx2 --replicas=5 --publish 81:80  --mount source=/etc/hostname,target=/usr/share/nginx/html/index.html,type=bind,ro nginx:1.12
a0qh801qdic51uyyguvpf15zh

On node1, use the watch utility to watch the update from the output of the docker service ps command:
$ watch -n 1 docker service ps nginx2

Click node3 and enter the command to leave the swarm cluster:
$ docker swarm leave


Click node1 to watch the reconciliation in action. You should see that the swarm attempts to get back to the declared state by rescheduling the containers that were running on node3 to node1 and node2 automatically.


/**********************************************************************************************
/**********************************************************************************************
Determine how many nodes you need
In this lab, your Docker Swarm cluster consists of one master and two worker nodes. 
This configuration is not highly available. 
The manager node contains the necessary information to manage the cluster, 
but if this node goes down, the cluster will cease to function. 
For a production application, you should provision a cluster with multiple manager nodes 
to allow for manager node failures.

You should have at least three manager nodes but typically no more than seven.
Manager nodes implement the raft consensus algorithm, which requires that more than 50% 
of the nodes agree on the state that is being stored for the cluster. 
If you don't achieve more than 50% agreement, the swarm will cease to operate correctly. 
For this reason, note the following guidance for node failure tolerance:
Three manager nodes tolerate one node failure.
Five manager nodes tolerate two node failures.
Seven manager nodes tolerate three node failures.

Remember these key points:
Docker Swarm schedules services by using a declarative language. You declare the state, 
and the swarm attempts to maintain and reconcile to make sure the actual state equals the desired state.

Docker Swarm is composed of manager and worker nodes. Only managers can maintain the state of 
the swarm and accept commands to modify it. Workers have high scalability and are only used to 
run containers. By default, managers can also run containers.

The routing mesh built into Docker Swarm means that any port that is published at the service level 
will be exposed on every node in the swarm. Requests to a published service port will be automatically 
routed to a container of the service that is running in the swarm.

You can use other tools to help solve problems with orchestrated, 
containerized applications in production, including Docker Swarm and the IBM Cloud Kubernetes Service.


##拉取一个镜像(image)
##拉取rabbitMQ镜像,如果本地不存在这个镜像，从远程仓库下载
docker pull rabbitmq:management




